---
title: "Final Project\n"
output: pdf_document
date: "May 2023\n"
author: "Imanbayeva Sofya, Mazzi Lapo, Piras Mattia, Srivastava Dev\n"
subtitle: "Group 22\n "
---

\newpage
```{r setup, include=FALSE, echo=TRUE}

#Setting up layout
knitr::opts_chunk$set(echo = FALSE, out.height = "75%", out.width = "75%", fig.align = "center")

#Downloading packages

list.of.packages <- c("dlm", "fpp2", "forecast","ggplot2","depmixS4","tidyverse","dplyr","rlang","tseries","zoo", "xts")
if(!require(dlm)){
    install.packages("dlm")
    library(dlm)
}
if(!require(fpp2)){
    install.packages("fpp2")
    library(fpp2)
}
if(!require(forecast)){
    install.packages("forecast")
    library(forecast)
}
if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}
if(!require(depmixS4)){
    install.packages("depmixS4")
    library(depmixS4)
}
if(!require(markovchain)){
    install.packages("markovchain")
    library(markovchain)
}
if(!require(tidyverse)){
    install.packages("tidyverse")
    library(tidyverse)
}
if(!require(dplyr)){
    install.packages("dplyr")
    library(dplyr)
}
if(!require(rlang)){
    install.packages("rlang")
    library(rlang)
}
  if(!require(tseries)){
    install.packages("tseries")
    library(tseries)
  }
  if(!require(zoo)){
    install.packages("zoo")
    library(zoo)
  }
if(!require(xts)){
    install.packages("xts")
    library(xts)
}
```


\newpage

# Question 1

We have chosen Station 55 for our analysis.

We will first present some time series plots to understand the data observed. After that we will fit a Gaussian HMM model and use it to interpret the first question of interest. 

# Data Visualization
```{r loading dataset, warning=FALSE, message= FALSE}

#Loading dataset

airdataset=read.csv("https://raw.githubusercontent.com/devpra1999/Time-Series-20236/main/ts_epa_2020_west_sept_fill.csv",header = TRUE)
attach(airdataset)

#Creating subset of data for station 55

st55datset= subset(airdataset,station_id==55)
st55datset$Time <- as.POSIXct(st55datset$datetime, format = "%Y-%m-%dT%H:%M:%SZ")
attach(st55datset)
```

```{r time series pm25}

#Creating time series for pm 25 levels at station 55

pm25ts <- zoo(st55datset$pm25, st55datset$datetime)
daily_avg_pm25 <- aggregate(pm25ts, as.Date(index(pm25ts)), mean)
daily_avg_ma_pm25 <- rollmean(daily_avg_pm25, k = 24, fill = NA)
plot(daily_avg_ma_pm25,main = "Graph 1: Average PM25 levels at station 55, 2020",cex.main=0.9, xlab = "Time", ylab= "Average PM25 level per day")

```

Moving average dramatically increases in the beginning of August from around 17 to its peak in the beginning of September at around 60 in its PM25 levels. The values slightly decrease in September.

```{r ts temp}
#Creating time series for temperatures at station 55

tempts <- zoo(st55datset$temp, st55datset$datetime)
daily_avg_t <- aggregate(tempts, as.Date(index(tempts)), mean)
daily_avg_ma_t <- rollmean(daily_avg_t, k = 24, fill = NA)
plot(daily_avg_ma_t, main = "Graph 2: Average Daily Temperature (C°) at station 55, 2020",cex.main=0.9, xlab = "Time", ylab= "Average Daily Temperature (C°)")
```

The temperature has been increasing from June's values of 24 degrees Celsius to its peak in August at around 28.

```{r ts wind}
#Creating time series for wind speed at station 55

windts <- zoo(st55datset$wind, st55datset$datetime)
daily_avg_w <- aggregate(windts, as.Date(index(windts)), mean)
daily_avg_ma_w <- rollmean(daily_avg_w, k = 24, fill = NA)
plot(daily_avg_ma_w, main = "Graph 3: Average Wind Speed (knots/second) at station 55, 2020", cex.main=0.9, xlab = "Time", ylab= "Average Wind Speed (knots/second)")
```

Average wind level has been stable at around 14m/s in the summer and started to decrease in the second part of August to around 12 in mid-September.

```{r compare}
#Creating graph for pm25, wind adùnd temperature at station 55

plot(scale(daily_avg_ma_pm25), col = "darkgreen", main = "Graph 4: Scaled development of PM25, temperature and wind, 2020", cex.main=0.9,xlab = "Time", ylab= "Scaled index")
lines(scale(daily_avg_ma_w), col = "blue")
lines(scale(daily_avg_ma_t), col = "red")
legend("bottomleft", legend = c("PM25","Wind", "Temp"), col = c("darkgreen","blue","red"), lty = c(1,1,1), cex = 0.5)
```

High average temperature in August and comparatively strong winds seem to have a correlation with fires, which have increased the values of PM25 particles in the air. There is around 10 day lag between the temperature increases and PM25 value increase in August.

```{r PM25 levels}

#Graph of pm25 at station 55 with dangerous levels

xmin = min(st55datset$Time)
xmax = max(st55datset$Time)
ymax = max(st55datset$pm25)

p <- ggplot(data=st55datset, aes(x=Time, y=pm25)) +
  ggtitle("Graph 5: PM2.5 levels at Station #55") +
  geom_rect(aes(xmin=xmin, xmax=xmax, ymin=25, ymax=ymax), fill=adjustcolor("pink",alpha.f=0.9), alpha=.2) +
  geom_line() +
  annotate(geom="text", x=as.POSIXct("2020-06-18"), y=200, label="Dangerous PM2.5 level", color="darkred", cex=3.5) +
  geom_hline(yintercept=25, color="darkred") + 
  scale_y_continuous(expand=c(0,0)) +
#  scale_x_date(limit=c(as.POSIXct("2020-06-01 00:00:00"),as.POSIXct("2020-09-30 23:00:00")))+
  labs(x=NULL, y=NULL)
p
```

Measurements from June to mid-August are smaller than the prescribed limit with the exception of a peak of an outlying 307.81 in July. 
However, since August until October, the dynamic has changed with only a few days where the values stayed within the limit constraints below 25 and most data being above the safe limit. The peaks are high, probably resulted from fires, high temperatures and strong wind.

```{r wind levels}
#Graph of wind strength

 windy <- ggplot(data=st55datset, aes(x=Time, y=wind)) +
   ggtitle("Graph 6: Wind strength") +
   geom_line() + 
   scale_y_continuous(expand=c(0,0)) +
#   scale_x_date(limit=c(as.Date("2020-06-01"),as.Date("2020-09-30")))+
   labs(x=NULL, y=NULL)
 windy
```

# Gaussian HMM Model
\begin{equation*}
\begin{cases}
Y_t = \mu_1 + \epsilon_t, \quad \epsilon_t \overset{iid}{\sim} N(0, \sigma_1^2)  
& \text{if the state $S_t=1$} \\
Y_t = \mu_2 + \epsilon_t, \quad \epsilon_t \overset{iid}{\sim} N(0, \sigma_2^2) 
&\text{if the state $S_t=2$}. \\

Y_t = \mu_3 + \epsilon_t, \quad \epsilon_t \overset{iid}{\sim} N(0, \sigma_3^2) 
& \text{if the state $S_t=3$} \\

\end{cases}
\end{equation*}
First, we set up our model. The initial probabilities and the transition matrix are just made by default values. Since, there are 3 states, they will have 1/3 probability each.
\[
\begin{tabular}{c|ccc}
State & 1 & 2 & 3 \\
\hline
Probability & $\pi_1$ & $\pi_2$ & $\pi_3$
\end{tabular}
\begin{equation*}
\begin{pmatrix}
p_0(1) = \frac{1}{3}\\

p_0(2) = \frac{1}{3} \\

p_0(3) = \frac{1}{3}
\end{pmatrix}
\end{equation*}
\]
```{r model}
#Computing initial probabilities and transition matrix 

set.seed(2)
y=as.numeric(st55datset$pm25)
model = depmix(y~ 1, data=data.frame(y), nstates=3)
cat('\n') 
```
The results of the estimation of both the initial probabilities and the transition matrix are indicated below.

```{r tables for initial probabilities }
#setting up table fo initial probabilities
table_matrix_2=matrix(c(0.333,0.333,0.333), nrow=1, ncol=3, byrow=T)
matrix_df <- as.data.frame(table_matrix_2)
row_labels_2 <- c("Prob. 1", "Prob. 2", "Prob. 3")
colnames(matrix_df) <- row_labels_2
table_title <- "Initial State probabilities"
knitr::kable(matrix_df, row.names = FALSE,caption=table_title)
```
```{r,initial transition probabilities }
#setting up table for initial transition probabilities
table_matrix_2=matrix(c(0.333,0.333,0.333,0.333,0.333,0.333,0.333,0.333,0.333), nrow=3, ncol=3, byrow=T)
column1 = c("From state 1","From state 2","From state 3")
matrix_df <- as.data.frame(table_matrix_2)
row_labels <- c("To state 1", "To state 2", "To state 3")
colnames(matrix_df) <- row_labels
Transition <- c("From state 1", "From state 2", "From state 3")
matrix_df <- cbind(Transition, matrix_df)
table_title <- "Initial transition transition probabilities of the states"
knitr::kable(matrix_df, row.names = FALSE,caption=table_title)

```

```{r,initial response parameters tables }
table_matrix_2=matrix(c("State 1",0,1,"State 2",0,1,"State 3",0,1), nrow=3, ncol=3, byrow=T)
matrix_df <- as.data.frame(table_matrix_2)
row_labels_2 <- c("", "Intercept", "Standard deviation")
colnames(matrix_df) <- row_labels_2
table_title <- "Initial mean and standard deviation of the states"
knitr::kable(matrix_df, row.names = FALSE,caption=table_title)
```

```{r,echo=FALSE, message=FALSE, results='hide'}
#fitting model 
fmodel <- fit(model)
```
```{r,echo=FALSE}
# Creating Initial state probabilities tables
MLEse <- standardError(fmodel)
coefficients2 = round(MLEse$par[1:3],3)
table_matrix_2=matrix(coefficients2, nrow=1, ncol=3, byrow=T)
matrix_df <- as.data.frame(table_matrix_2)
row_labels_2 <- c("Prob. 1", "Prob. 2", "Prob. 3")
colnames(matrix_df) <- row_labels_2
table_title <- "Initial State probabilities"
knitr::kable(matrix_df, row.names = FALSE,caption=table_title)

```

```{r,echo=FALSE}

# Creating a transition matrix  table
MLEse <- standardError(fmodel)
coefficients1 = round(MLEse$par[4:12],3)
table_matrix_2=matrix(coefficients1, nrow=3, ncol=3, byrow=T)
column1 = c("From state 1","From state 2","From state 3")
matrix_df <- as.data.frame(table_matrix_2)
row_labels <- c("To state 1", "To state 2", "To state 3")
colnames(matrix_df) <- row_labels
Transition <- c("From state 1", "From state 2", "From state 3")
matrix_df <- cbind(Transition, matrix_df)
table_title <- "Estimated transition probabilities of the states^[The probabilities were estimated through MLE]  "
knitr::kable(matrix_df, row.names = FALSE,caption=table_title)
```

```{r,echo=FALSE}  
#creating response parameter coefficients

MLEse <- standardError(fmodel)
coefficients <- round(MLEse$par[13:18], 3)
standard_errors <- round(MLEse$se[13:18], 3)

#creating confidence interval 
upper_bound= coefficients + 1.984*standard_errors
lower_bound= coefficients - 1.984*standard_errors

# Creating response parameter table

labels <- c("St1 Intercept", "State 1 Standard Deviation", "St2 Intercept", "State 2 Standard Deviation", "St3 Intercept", "State 3 Standard Deviation")
table_matrix <- matrix(nrow = 6, ncol = 4)

table_matrix[1:6, 1] <- coefficients
table_matrix[1:6, 2] <- standard_errors
table_matrix[1:6,3] = upper_bound
table_matrix[1:6,4] = lower_bound
table_data <- data.frame(Label = labels, table_matrix)
title <- "MLE estimates of the mean and standard deviation of the states^[Upper and lower bound computed at the 95% confidence level]"
colnames(table_data) <- c("", "Coefficient", "Standard Error", "Upper Bound", "Lower Bound")
knitr::kable(table_data, col.names = colnames(table_data), caption = title)

```

Firstly, we can identify the three states that we wanted to study. State 1 is the one relative to low pollution, state 3 is relative to high pollution levels and state 2 is the one that we can associate to a medium pollution levels. Looking at the transition matrix we note that there are steps that are never possible, state 3 to 1 and vice versa.

Further, the states are very persistent, and probability of state transition by a single step is very low, and by two steps virtually zero. Thus, the current state is a very good predictor of the state in the next hour.

If the current state is of low pollution, there is not much need to enforce any strict measures, with an extremely high probability (0.993) of staying the same low pollution state.

If the current state is of medium pollution, there is a need to enforce strict measures for some time, given the large probability of staying in the medium state (0.95), and also a possibility of transitioning to high pollution state in the next hour(0.026).

Finally, if the pollution is high prolonged strict measures should be anticipated to bring it down medium pollution and finally to low pollution (prolonged because) both high and medium pollution states being highly persistent.

The following table gives the expected number of hours for pollution state to move from i to j (where i and j are different).

```{r future hours}
#Expected number of hours to move from one state to other

tpm <- getpars(fmodel)[4:12]
mcpm25 <- new("markovchain", states = c("Low","Medium","High"), transitionMatrix = matrix(data=tpm, byrow=TRUE, nrow=3), name="PM25")
meanFirstPassageTime(mcpm25)
```

Thus we can see that if the current state is of high pollution, it'll take an expected time of 92 hours for the pollution to reach the low pollution state and 23 hours to reach the medium pollution state. Again given the persistence of each state, the first passage time is a good metric for predicting outcomes over the next hours.

Finally, below is the prediction of the states, given the data observed.

```{r,comment="",warning=FALSE}

#Creating estates variable

estStates <- posterior(fmodel)
```

```{r, out.width='100%'}

#State predictions graph

plot(as.POSIXct(st55datset$datetime), estStates[,1],ylab= "Predicted State", xlab="Time" ,  cex=.3, type="s", main="Graph 7: State predictions") 
```

# Question 2 

For our analysis we decided to use stations 55, 92, 97 and 41.


```{r setting up time series}

#Setting up the time series for each station 

st97datset <- subset(airdataset, station_id == 97)
st97datset$Time <- as.POSIXct(st97datset$datetime, format = "%Y-%m-%dT%H:%M:%SZ")
ts97 <- xts(st97datset$pm25, order.by = st97datset$Time)
log_ts97 <- log(ts97)
log_ts97_zoo <- as.zoo(log_ts97)
log_ts97_avg <- rollmean(log_ts97_zoo, k = 12, fill = NA)

st55datset <- subset(airdataset, station_id == 55)
st55datset$Time <- as.POSIXct(st55datset$datetime, format = "%Y-%m-%dT%H:%M:%SZ")
ts55 <- xts(st55datset$pm25, order.by = st55datset$Time)
log_ts55 <- log(ts55)
log_ts55_zoo <- as.zoo(log_ts55)
log_ts55_avg <- rollmean(log_ts55_zoo, k = 12, fill = NA)

st92datset <- subset(airdataset, station_id == 92)
st92datset$Time <- as.POSIXct(st92datset$datetime, format = "%Y-%m-%dT%H:%M:%SZ")
ts92 <- xts(st92datset$pm25, order.by = st92datset$Time)
log_ts92 <- log(ts92)
log_ts92_zoo <- as.zoo(log_ts92)
log_ts92_avg <- rollmean(log_ts92_zoo, k = 12, fill = NA)

st41datset <- subset(airdataset, station_id == 41)
st41datset$Time <- as.POSIXct(st41datset$datetime, format = "%Y-%m-%dT%H:%M:%SZ")
ts41 <- xts(st41datset$pm25, order.by = st41datset$Time)
log_ts41 <- log(ts41)
log_ts41_zoo <- as.zoo(log_ts41)
log_ts41_avg <- rollmean(log_ts41_zoo, k = 12, fill = NA)
```

```{r, Graph 8}
#Setting up graph 8

plot(log_ts55_avg, col = "red", main = "Graph 8: PM2.5 levels at station 41 and 55", cex.main=0.9, xlab="Time" ,ylab= "PM2.5 level (log of)")
lines(log_ts41_avg, col = "black")
legend("topleft", legend = c("Station 41","Station 55"), col = c("black","red"), lty = c(1,1), cex = 0.5)
```


```{r, Graph 9}

#Setting up graph 9

plot(log_ts92_avg, col = "red", main = "Graph 9: PM2.5 levels at station 92 and 97", cex.main=0.9, xlab="Time" ,ylab= "PM2.5 level (log of)")
lines(log_ts97_avg, col = "black")
legend("topleft", legend = c("Station 97","Station 92"), col = c("black","red"), lty = c(1,1), cex = 0.5)
```


```{r, Graph 10}

#Setting up graph 10

plot(log_ts41_avg, col = "black", main = "Graph 10: PM2.5 levels at station 92 and 41", cex.main=0.9,xlab="Time" , ylab= "PM2.5 level (log of)")
lines(log_ts92_avg, col = "red")
legend("topleft", legend = c("Station 41","Station 92"), col = c("black","red"), lty = c(1,1), cex = 0.5)
```

In case of spatial dependence we expect the graphs of the closer stations to be more aligned compared to the ones which are more distant. Stations 55 and 41 are the closest one (only 100km apart) and we can see from Graph 8 that their measurement of pm25 almost coincide, supporting the spatial dependency hypothesis. Stations 92 and 97 are almost 300 km apart, and we can see from Graph  9 that their overlap is lower compared to the previous figure. This is even more clear if we look at Graph 10. Stations 41 and 92 are the furthest apart (650 km) and we can see that their observations are the less synchronized, especially in the Autumn months. Thus, we can affirm from this rough first analysis that there is the case for a phenomenon of spatial dependence. 

# Model specification

To set up a model that accounts for the spatial dependency we first need a formula to calculate the distance between stations. We decided to use the geometrical based on the coordinates of the stations.

$$
distance_{i,j} = \sqrt{{(long_{i}-long_{j} )^2 + (lat_{i}-lat_{j})^2}}
$$

```{r}
#Combine datasets
df <- as.ts(merge.zoo(log_ts41_avg,log_ts55_avg,log_ts92_zoo,log_ts97_avg))

#Location of stations
s41 <- c(37.79339,-121.2479)
s55 <- c(37.28185,-120.4337)
s92 <- c(33.71969,-116.1897)
s97 <- c(36.16976,-115.263)
list_st <- list(s41,s55,s92,s97)

#Number of stations
m=4
#Number of states
p=2

#Function for calculating distance
distance <- function(s1, s2) {
  lat_diff <- s1[1] - s2[1]
  lon_diff <- s1[2] - s2[2]
  sqrt(lat_diff^2 + lon_diff^2)
}

#Make matrix of distances
D = matrix(nrow = m,ncol = m)
for (i in 1:m){
  for (j in 1:m){
    D[i,j] <- distance(list_st[[i]],list_st[[j]])
  }
}

```
$$
\begin{cases}
\begin{aligned}
Y_t &= F \theta_t + v_t \quad & v_t  \overset{indep}\sim N_m(\textbf{0}, V) \\
\theta_t &= G \theta_t + w_t, \quad & w_t \overset{indep}\sim N_p(\textbf{0}, W) 
\end{aligned}
\end{cases}
$$
```{r}
#Model specification
build <- function(parm){
  #p=2,m=4
  mod <- dlmModPoly(order = p)
  mod$FF <- mod$FF %x% diag(m)
  mod$GG <- mod$GG %x% diag(m)
  mod$V = diag(parm[1:m])
  W1 <- parm[m+1] * exp(-parm[m+2]*D)
  W2 <- parm[m+3] * exp(-parm[m+4]*D)
  #W3 <- parm[m+5] * exp(-parm[m+6]*D)
  mod$W <- bdiag(W1, W2)
  mod$m0 <- rep(0, m*p)
  mod$C0 <- diag(m*p)*1e-5
  return(mod)
}
#MLE
k <- m + 2*p #Number of parameters - m for V and 2 for each state's W
fit <- dlmMLE(df,rep(0.2,k),build,lower = rep(1e-6,k))
fit$convergence
fit$value #MLE negative loglikelihood value
fit$par
unlist(build(fit$par)[c("V", "W")])

#Building a model
mod_dlm <- build(fit$par)
mod_dlm$V

#Filtering
outFilt <- dlmFilter(df, mod_dlm)
fc <- dlmForecast(outFilt,nAhead=1)
fc
forecast_theta2 <- round(fc$a[1:4],3)
forecast_theta1 <- round(fc$a[5:8],3)
forecast_y <- round(fc$f,3)
labels <- c("State 1 Expected Value", "State 2 Expected Value", "1 Step Ahead Prediction")

# Creating response parameter table
table_matrix <- matrix(nrow = 3, ncol = 4)
table_matrix[3, 1:4] <- forecast_y
table_matrix[1, 1:4] <- forecast_theta1
table_matrix[2, 1:4] <- forecast_theta2
table_data <- data.frame(label=labels, table_matrix)
knitr::kable(table_data, col.names = c("Label","Station41","Station55","Station92","Station97"))
```

Clearly, the values for State 2 Expected Value and one-step-ahead prediction are the same, as it seems that for all stations, the value of PM2.5 is expected to be high. 

